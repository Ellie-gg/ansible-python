{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def main():\n",
    "    ass_main = le_assinatura()\n",
    "    textos_main = le_textos()\n",
    "    matriz_ass = calcula_assinatura(textos_main)\n",
    "    ass_comparadas = compara_assinatura(ass_main, matriz_ass)\n",
    "    copiah = avalia_textos(textos_main, ass_comparadas) + 1\n",
    "    return print(\"O autor do texto\", copiah, \"está infectado com COH-PIAH.\")\n",
    "\n",
    "\n",
    "def le_assinatura():\n",
    "\n",
    "    print(\"Bem-vindo ao detector automático de COH-PIAH.\")\n",
    "\n",
    "    tam_m_pal = float(input(\"Entre o tamanho medio de palavra:\"))\n",
    "    type_token = float(input(\"Entre a relação Type-Token:\"))\n",
    "    h_lego = float(input(\"Entre a Razão Hapax Legomana:\"))\n",
    "    tam_m_sent = float(input(\"Entre o tamanho médio de sentença:\"))\n",
    "    compx_med = float(input(\"Entre a complexidade média da sentença:\"))\n",
    "    tam_m_frase = float(input(\"Entre o tamanho medio de frase:\"))\n",
    "\n",
    "    return [tam_m_pal, type_token, h_lego, tam_m_sent, compx_med, tam_m_frase]\n",
    "\n",
    "\n",
    "def le_textos():\n",
    "    i = 1\n",
    "    textos = []\n",
    "    texto = input(\"Digite o texto \" + str(i) + \"(aperte enter para sair):\")\n",
    "    while texto:\n",
    "        textos.append(texto)\n",
    "        i += 1\n",
    "        texto = input(\"Digite o texto \" + str(i) + \"(aperte enter para sair):\")\n",
    "\n",
    "    return textos\n",
    "\n",
    "\n",
    "def calcula_assinatura(texto):\n",
    "\n",
    "    if type(texto) != list:\n",
    "        aux = texto\n",
    "        texto = []\n",
    "        texto.append(aux)\n",
    "    matriz_ass_input = []\n",
    "    for i in texto:\n",
    "        sentencas = []\n",
    "        sentencas = separa_sentencas(str(i))  # sent.. = lista comum, ~matriz\n",
    "        frases = []\n",
    "        num_tot_sentencas = 0\n",
    "        soma_cat_sentencas = 0\n",
    "        for i in range(len(sentencas)):\n",
    "            frase_i = separa_frases(str(sentencas[i]))\n",
    "            frases.append(frase_i)  # frases = matriz, lista de listas\n",
    "            num_tot_sentencas += 1\n",
    "            soma_cat_sentencas = soma_cat_sentencas + len(sentencas[i])\n",
    "        palavras = []\n",
    "        num_tot_frases = 0\n",
    "        soma_cat_frases = 0\n",
    "        for lin in range(len(frases)):\n",
    "            for col in range(len(frases[lin])):\n",
    "                palavra_i = separa_palavras(str(frases[lin][col]))\n",
    "                palavras.append(palavra_i)  # palav.. = matriz, lista de listas\n",
    "                num_tot_frases += 1\n",
    "                soma_cat_frases = soma_cat_frases + len(str(frases[lin][col]))\n",
    "        mtrx_para_lista = []  # transform.. palavras de matriz para lista\n",
    "        for lin in range(len(palavras)):\n",
    "            for col in range(len(palavras[lin])):\n",
    "                mtrx_para_lista.append(palavras[lin][col])\n",
    "        palavras = mtrx_para_lista[:]\n",
    "        soma_comp_palavras = 0\n",
    "        num_tot_palavras = 0\n",
    "        for lin in range(len(palavras)):\n",
    "            for col in range(len(palavras[lin])):\n",
    "                soma_comp_palavras = soma_comp_palavras + len(str(palavras[lin][col]))\n",
    "            num_tot_palavras += 1\n",
    "        ass_txt = []\n",
    "        ass_txt.append(tam_m_pal(soma_comp_palavras, num_tot_palavras))\n",
    "        ass_txt.append(type_token(palavras, num_tot_palavras))\n",
    "        ass_txt.append(h_lego(palavras, num_tot_palavras))\n",
    "        ass_txt.append(tam_m_sent(soma_cat_sentencas, num_tot_sentencas))\n",
    "        ass_txt.append(compx_med(num_tot_frases, num_tot_sentencas))\n",
    "        ass_txt.append(tam_m_frase(soma_cat_frases, num_tot_frases))\n",
    "        matriz_ass_input.append(ass_txt)\n",
    "    return matriz_ass_input  # matriz, lista de listas dos valores das assina..\n",
    "\n",
    "\n",
    "def tam_m_pal(soma_comp_palavras, num_tot_palavras):\n",
    "    if num_tot_palavras != 0:\n",
    "        tam_m_pal = soma_comp_palavras / num_tot_palavras\n",
    "    else:\n",
    "        tam_m_pal = 0\n",
    "    return tam_m_pal\n",
    "\n",
    "\n",
    "def type_token(lista_palavras, num_tot_palavras):\n",
    "    num_pal_dif = n_palavras_diferentes(lista_palavras)\n",
    "    if num_tot_palavras != 0:\n",
    "        type_token = num_pal_dif / num_tot_palavras\n",
    "    else:\n",
    "        type_token = 0\n",
    "    return type_token\n",
    "\n",
    "\n",
    "def h_lego(lista_palavras, num_tot_palavras):\n",
    "    num_pal_uni = n_palavras_unicas(lista_palavras)\n",
    "    if num_tot_palavras != 0:\n",
    "        h_lego = num_pal_uni / num_tot_palavras\n",
    "    else:\n",
    "        h_lego = 0\n",
    "    return h_lego\n",
    "\n",
    "\n",
    "def tam_m_sent(soma_num_cat, num_sent):\n",
    "    if num_sent != 0:\n",
    "        tam_m_sent = soma_num_cat / num_sent\n",
    "    else:\n",
    "        tam_m_sent = 0\n",
    "    return tam_m_sent\n",
    "\n",
    "\n",
    "def compx_med(num_tot_frases, num_tot_sentencas):\n",
    "    if num_tot_sentencas != 0:\n",
    "        compx_med = num_tot_frases / num_tot_sentencas\n",
    "    else:\n",
    "        compx_med = 0\n",
    "    return compx_med\n",
    "\n",
    "\n",
    "def tam_m_frase(soma_cat_frases, num_tot_frases):\n",
    "    if num_tot_frases != 0:\n",
    "        tam_m_frase = soma_cat_frases / num_tot_frases\n",
    "    else:\n",
    "        tam_m_frase = 0\n",
    "    return tam_m_frase\n",
    "\n",
    "\n",
    "def separa_sentencas(texto):\n",
    "    \n",
    "    sentencas = re.split(r'[.!?]+', texto)\n",
    "    if sentencas[-1] == '':\n",
    "        del sentencas[-1]\n",
    "    return sentencas\n",
    "\n",
    "\n",
    "def separa_frases(sentenca):\n",
    "  \n",
    "    return re.split(r'[,:;]+', sentenca)\n",
    "\n",
    "\n",
    "def separa_palavras(frase):\n",
    "   \n",
    "    return frase.split()\n",
    "\n",
    "\n",
    "def n_palavras_unicas(lista_palavras):\n",
    "    \n",
    "    freq = dict()\n",
    "    unicas = 0\n",
    "    for palavra in lista_palavras:\n",
    "        p = palavra.lower()\n",
    "        if p in freq:\n",
    "            if freq[p] == 1:\n",
    "                unicas -= 1\n",
    "            freq[p] += 1\n",
    "        else:\n",
    "            freq[p] = 1\n",
    "            unicas += 1\n",
    "\n",
    "    return unicas\n",
    "\n",
    "\n",
    "def n_palavras_diferentes(lista_palavras):\n",
    "\n",
    "    freq = dict()\n",
    "    for palavra in lista_palavras:\n",
    "        p = palavra.lower()\n",
    "        if p in freq:\n",
    "            freq[p] += 1\n",
    "        else:\n",
    "            freq[p] = 1\n",
    "\n",
    "    return len(freq)\n",
    "\n",
    "\n",
    "def compara_assinatura(ass_main, matriz_ass_input):\n",
    " \n",
    "    lista_Sab = []\n",
    "    soma_mod = 0\n",
    "    if type(matriz_ass_input[0]) is list:\n",
    "        for lin in range(len(matriz_ass_input)):\n",
    "            for col in range(len(matriz_ass_input[lin])):\n",
    "                soma_mod += abs(ass_main[col] - matriz_ass_input[lin][col])\n",
    "            Sab = soma_mod / 6\n",
    "            lista_Sab.append(Sab)\n",
    "        return lista_Sab\n",
    "    else:\n",
    "        for i in range(len(matriz_ass_input)):\n",
    "            soma_mod += abs(ass_main[i] - matriz_ass_input[i])\n",
    "        Sab = soma_mod / 6\n",
    "        return Sab\n",
    "\n",
    "\n",
    "def avalia_textos(textos_main, ass_comparadas):\n",
    "  \n",
    "    aux_ass_com = ass_comparadas[:]\n",
    "    aux_ass_com.sort()\n",
    "    for indice in range(len(ass_comparadas)):\n",
    "        if aux_ass_com[0] == ass_comparadas[indice]:\n",
    "            copiah = indice\n",
    "    return copiah -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'le_texto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-45ca32694f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mle_texto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'le_texto' is not defined"
     ]
    }
   ],
   "source": [
    "le_texto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite o texto 1(aperte enter para sair):hoejaljaf lkajslkfja\n",
      "Digite o texto 2(aperte enter para sair):lkajsflka\n",
      "Digite o texto 3(aperte enter para sair):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hoejaljaf lkajslkfja', 'lkajsflka']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_textos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "avalia_textos() missing 2 required positional arguments: 'textos_main' and 'ass_comparadas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4ec921007cfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mavalia_textos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: avalia_textos() missing 2 required positional arguments: 'textos_main' and 'ass_comparadas'"
     ]
    }
   ],
   "source": [
    "avalia_textos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
